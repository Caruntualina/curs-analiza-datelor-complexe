{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9f38d-656c-47ce-98c3-ee58bb6c5087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00fc50-48a9-4bd9-a29c-efc70bf0986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62bc80-5f17-49a8-9afb-0ae08cf853eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "# data = open('../data/input/poezii.txt').read()\n",
    "data = open('../data/input/21pilots.txt').read()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4c39a-def6-4ca2-af0d-166e198d9366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bb299-2f3b-41d8-ad5b-1ff4f3fabbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenizer.word_index['wish'])\n",
    "print(tokenizer.word_index['momma'])\n",
    "print(tokenizer.word_index['stressed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ef6d6-bd2e-4551-8ab9-8c70ccc132d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da9fe1-eb4d-49e5-93f2-69449c06500f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c8d5b-a7aa-44b1-9300-0bf15187bdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "history = model.fit(xs, ys, epochs=30, verbose=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089be3a-f234-4323-8afd-9d66d5e5ba8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73bb1dd-b571-4563-a9cd-8b3638d456ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_text = \"flowers in a car\"\n",
    "next_words = 10\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1db89f-f754-499c-a284-8e2874c335f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py_310",
   "language": "python",
   "name": "nlp_py_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
